{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 229781 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_012          229781 non-null  int32  \n",
      " 1   HighBP                229781 non-null  float64\n",
      " 2   HighChol              229781 non-null  float64\n",
      " 3   CholCheck             229781 non-null  float64\n",
      " 4   BMI                   229781 non-null  float64\n",
      " 5   Smoker                229781 non-null  float64\n",
      " 6   Stroke                229781 non-null  float64\n",
      " 7   HeartDiseaseorAttack  229781 non-null  float64\n",
      " 8   PhysActivity          229781 non-null  float64\n",
      " 9   Fruits                229781 non-null  float64\n",
      " 10  Veggies               229781 non-null  float64\n",
      " 11  HvyAlcoholConsump     229781 non-null  float64\n",
      " 12  AnyHealthcare         229781 non-null  float64\n",
      " 13  NoDocbcCost           229781 non-null  float64\n",
      " 14  GenHlth               229781 non-null  int32  \n",
      " 15  MentHlth              229781 non-null  float64\n",
      " 16  PhysHlth              229781 non-null  float64\n",
      " 17  DiffWalk              229781 non-null  float64\n",
      " 18  Sex                   229781 non-null  float64\n",
      " 19  Age                   229781 non-null  int32  \n",
      " 20  Education             229781 non-null  int32  \n",
      " 21  Income                229781 non-null  int32  \n",
      "dtypes: float64(17), int32(5)\n",
      "memory usage: 35.9 MB\n",
      "(229781, 21)\n",
      "(229781,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_4</th>\n",
       "      <th>Education_5</th>\n",
       "      <th>Education_6</th>\n",
       "      <th>Income_2</th>\n",
       "      <th>Income_3</th>\n",
       "      <th>Income_4</th>\n",
       "      <th>Income_5</th>\n",
       "      <th>Income_6</th>\n",
       "      <th>Income_7</th>\n",
       "      <th>Income_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229781 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0          1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1          0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2          1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3          1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4          1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "...        ...       ...        ...   ...     ...     ...   \n",
       "253675     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  Education_4  \\\n",
       "0                        0.0           0.0     0.0      1.0  ...         True   \n",
       "1                        0.0           1.0     0.0      0.0  ...        False   \n",
       "2                        0.0           0.0     1.0      0.0  ...         True   \n",
       "3                        0.0           1.0     1.0      1.0  ...        False   \n",
       "4                        0.0           1.0     1.0      1.0  ...        False   \n",
       "...                      ...           ...     ...      ...  ...          ...   \n",
       "253675                   0.0           0.0     1.0      1.0  ...        False   \n",
       "253676                   0.0           0.0     0.0      0.0  ...        False   \n",
       "253677                   0.0           1.0     1.0      0.0  ...        False   \n",
       "253678                   0.0           0.0     1.0      1.0  ...        False   \n",
       "253679                   1.0           1.0     1.0      0.0  ...        False   \n",
       "\n",
       "        Education_5  Education_6  Income_2  Income_3  Income_4  Income_5  \\\n",
       "0             False        False     False      True     False     False   \n",
       "1             False         True     False     False     False     False   \n",
       "2             False        False     False     False     False     False   \n",
       "3             False        False     False     False     False     False   \n",
       "4              True        False     False     False      True     False   \n",
       "...             ...          ...       ...       ...       ...       ...   \n",
       "253675        False         True     False     False     False     False   \n",
       "253676        False        False     False     False      True     False   \n",
       "253677         True        False      True     False     False     False   \n",
       "253678         True        False     False     False     False     False   \n",
       "253679        False         True      True     False     False     False   \n",
       "\n",
       "        Income_6  Income_7  Income_8  \n",
       "0          False     False     False  \n",
       "1          False     False     False  \n",
       "2          False     False      True  \n",
       "3           True     False     False  \n",
       "4          False     False     False  \n",
       "...          ...       ...       ...  \n",
       "253675     False      True     False  \n",
       "253676     False     False     False  \n",
       "253677     False     False     False  \n",
       "253678     False     False     False  \n",
       "253679     False     False     False  \n",
       "\n",
       "[229781 rows x 45 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## read the raw data file\n",
    "df = pd.read_csv('raw_data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "df.head()\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# convert data types\n",
    "df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']] = df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']].astype(int)\n",
    "df.info()\n",
    "\n",
    "#slice the dataframe for feature and label\n",
    "df_copy = df.copy(deep=True)\n",
    "X, y = df_copy.iloc[:,1:], df_copy.iloc[:,0]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#get dummies\n",
    "def get_dummies(X):\n",
    "\n",
    "    # Identify discrete columns with more than 2 categories\n",
    "    discrete_columns = [col for col in X.columns if X[col].nunique() > 2 and X[col].dtype != 'float64']\n",
    "\n",
    "    # Create dummy variables for these columns\n",
    "    df_with_dummies = pd.get_dummies(X, columns=discrete_columns, drop_first=True)\n",
    "\n",
    "    return df_with_dummies\n",
    "X = get_dummies(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving forward with l2 logistic regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# define oversampling strategy\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_over, y_over = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012\n",
       "0    114033\n",
       "2    114033\n",
       "1    114033\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## oversample succeed\n",
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_over)\n",
    "X_scaled_test = scalar.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [0]\n",
      "accuracy : 0.8271082436652052  precision : 0.2757027478884017 \n",
      " recall : 0.3333333333333333  f1 : 0.30179136769186493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14294\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## This is the baseline dummy classifier which classifies all as the majority class\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_scaled, y_over)\n",
    "y_dummy_prediction = dummy_majority.predict(X_scaled_test)\n",
    "\n",
    "## calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_dummy_prediction)\n",
    "precision = precision_score(y_test, y_dummy_prediction, average='macro')\n",
    "recall = recall_score(y_test, y_dummy_prediction, average='macro')\n",
    "f1 = f1_score(y_test, y_dummy_prediction, average='macro')\n",
    "print('Unique predicted labels: ', (np.unique(y_dummy_prediction)))\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.5120820776168769  precision : 0.427849567900942 \n",
      " recall : 0.4953694647263758  f1 : 0.36834357146141694\n",
      "[[36400 16033 23589]\n",
      " [  268   528  1056]\n",
      " [ 1058  2842 10139]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14294\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Moving forward with l2 logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training the logistic regression model\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "\n",
    "clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = clf.predict(X_scaled_test)\n",
    "y_pred_proba = clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9649    0.4788    0.6400     76022\n",
      "           1     0.0272    0.2851    0.0497      1852\n",
      "           2     0.2915    0.7222    0.4153     14039\n",
      "\n",
      "    accuracy                         0.5121     91913\n",
      "   macro avg     0.4278    0.4954    0.3683     91913\n",
      "weighted avg     0.8431    0.5121    0.5938     91913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Making predictions\n",
    "y_pred = clf.predict(X_scaled_test)\n",
    "y_pred_proba = clf.predict_proba(X_scaled_test)[:, 1]\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6342737153612655  precision : 0.39516545638654027 \n",
      " recall : 0.43791832807167125  f1 : 0.3866003068687975\n"
     ]
    }
   ],
   "source": [
    "## we can see that the baseline model logistic regression perform poorly\n",
    "## try KNN classifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Setting up the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = knn.predict(X_scaled_test)\n",
    "y_pred_proba = knn.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8968    0.6578    0.7590     76022\n",
      "           1     0.0304    0.0756    0.0434      1852\n",
      "           2     0.2583    0.5803    0.3575     14039\n",
      "\n",
      "    accuracy                         0.6343     91913\n",
      "   macro avg     0.3952    0.4379    0.3866     91913\n",
      "weighted avg     0.7818    0.6343    0.6832     91913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Making predictions\n",
    "y_pred = knn.predict(X_scaled_test)\n",
    "y_pred_proba = knn.predict_proba(X_scaled_test)[:, 1]\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.741179158552109  precision : 0.3901165541610552 \n",
      " recall : 0.3952510754252576  f1 : 0.3922671932446807\n"
     ]
    }
   ],
   "source": [
    "## we can see that both logistic regression and KNN perform very poorly, lets try more models\n",
    "\n",
    "## Decision trees\n",
    "from sklearn import tree\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = tree_clf.predict(X_scaled_test)\n",
    "y_pred_proba = tree_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear support vector classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC(kernel='rbf')\n",
    "svc_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svc_clf.predict(X_scaled_test)\n",
    "y_pred_proba = svc_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14294\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.5394340300066367  precision : 0.4270586302986541 \n",
      " recall : 0.49770810546244276  f1 : 0.3784217732136291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\14294\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## linear support vector classifier (Using LinearSVC from sklearn)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_clf = LinearSVC()\n",
    "svc_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svc_clf.predict(X_scaled_test)\n",
    "#y_pred_proba = svc_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.5327755594964804  precision : 0.4073497198873093 \n",
      " recall : 0.46668347828756246  f1 : 0.35751672080133295\n"
     ]
    }
   ],
   "source": [
    "## implement the naive bayes algorithm\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = NB_clf.predict(X_scaled_test)\n",
    "y_pred_proba = NB_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8160760719375931  precision : 0.4482228834990453 \n",
      " recall : 0.4216996556795238  f1 : 0.42737202376126143\n"
     ]
    }
   ],
   "source": [
    "## random forest prediction\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "rf_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = rf_clf.predict(X_scaled_test)\n",
    "y_pred_proba = rf_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6099463623208904  precision : 0.4399065031337583 \n",
      " recall : 0.5078198162952487  f1 : 0.41478480375734333\n"
     ]
    }
   ],
   "source": [
    "## gradient boosing decision trees (GBDT)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBDT_clf = GradientBoostingClassifier(n_estimators=300)\n",
    "GBDT_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = GBDT_clf.predict(X_scaled_test)\n",
    "y_pred_proba = GBDT_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6099790018822147  precision : 0.4403567115153774 \n",
      " recall : 0.5087442013509339  f1 : 0.41530388427371195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=300)\n",
    "ada_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = ada_clf.predict(X_scaled_test)\n",
    "y_pred_proba = ada_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.fc1 = nn.Linear(45, 64)\n",
    "        # Second hidden layer\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        # Third hidden layer\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        # Output layer\n",
    "        self.fc4 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply ReLU activation function after each hidden layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # Apply softmax to the output layer\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming X and y are your features and labels respectively\n",
    "# Convert your data to PyTorch tensors if they are not already\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_over, dtype=torch.int64)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 183824  # You can adjust this according to your needs\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "X_tensor_test = torch.tensor(X_scaled_test, dtype=torch.float32)\n",
    "y_tensor_test = torch.tensor(y_test.to_numpy(), dtype=torch.int64)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor_test, y_tensor_test)\n",
    "\n",
    "# Create a DataLoader\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "model = NeuralNetwork()\n",
    "# model = model.to('mps:0')\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    return recall\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(500):  # num_epochs is the number of times you go through the entire dataset\n",
    "    # all_predictions = []\n",
    "    # all_labels = []\n",
    "    for batch in train_loader:  # data_loader is your PyTorch DataLoader with training data\n",
    "        inputs, labels = batch\n",
    "        # inputs = inputs.to('mps:0')\n",
    "        # labels = labels.to('mps:0')\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    recall = evaluate_model(model, test_loader)\n",
    "    print(f'Epoch {epoch+1}/500, Loss: {loss.item():.4f}, Macro Recall: {recall:.4f}')\n",
    "\n",
    "\n",
    "    #     _, predicted = torch.max(outputs.data, 1)\n",
    "    #     all_predictions.extend(predicted.cpu().numpy())\n",
    "    #     all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # # Calculate recall\n",
    "    # recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    # print(f'Epoch [{epoch+1}/{500}], Loss: {loss.item():.4f}, Recall: {recall:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
