{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 229781 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_012          229781 non-null  int64  \n",
      " 1   HighBP                229781 non-null  float64\n",
      " 2   HighChol              229781 non-null  float64\n",
      " 3   CholCheck             229781 non-null  float64\n",
      " 4   BMI                   229781 non-null  float64\n",
      " 5   Smoker                229781 non-null  float64\n",
      " 6   Stroke                229781 non-null  float64\n",
      " 7   HeartDiseaseorAttack  229781 non-null  float64\n",
      " 8   PhysActivity          229781 non-null  float64\n",
      " 9   Fruits                229781 non-null  float64\n",
      " 10  Veggies               229781 non-null  float64\n",
      " 11  HvyAlcoholConsump     229781 non-null  float64\n",
      " 12  AnyHealthcare         229781 non-null  float64\n",
      " 13  NoDocbcCost           229781 non-null  float64\n",
      " 14  GenHlth               229781 non-null  int64  \n",
      " 15  MentHlth              229781 non-null  float64\n",
      " 16  PhysHlth              229781 non-null  float64\n",
      " 17  DiffWalk              229781 non-null  float64\n",
      " 18  Sex                   229781 non-null  float64\n",
      " 19  Age                   229781 non-null  int64  \n",
      " 20  Education             229781 non-null  int64  \n",
      " 21  Income                229781 non-null  int64  \n",
      "dtypes: float64(17), int64(5)\n",
      "memory usage: 40.3 MB\n",
      "(229781, 21)\n",
      "(229781,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_4</th>\n",
       "      <th>Education_5</th>\n",
       "      <th>Education_6</th>\n",
       "      <th>Income_2</th>\n",
       "      <th>Income_3</th>\n",
       "      <th>Income_4</th>\n",
       "      <th>Income_5</th>\n",
       "      <th>Income_6</th>\n",
       "      <th>Income_7</th>\n",
       "      <th>Income_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229781 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0          1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1          0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2          1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3          1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4          1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "...        ...       ...        ...   ...     ...     ...   \n",
       "253675     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  Education_4  \\\n",
       "0                        0.0           0.0     0.0      1.0  ...            1   \n",
       "1                        0.0           1.0     0.0      0.0  ...            0   \n",
       "2                        0.0           0.0     1.0      0.0  ...            1   \n",
       "3                        0.0           1.0     1.0      1.0  ...            0   \n",
       "4                        0.0           1.0     1.0      1.0  ...            0   \n",
       "...                      ...           ...     ...      ...  ...          ...   \n",
       "253675                   0.0           0.0     1.0      1.0  ...            0   \n",
       "253676                   0.0           0.0     0.0      0.0  ...            0   \n",
       "253677                   0.0           1.0     1.0      0.0  ...            0   \n",
       "253678                   0.0           0.0     1.0      1.0  ...            0   \n",
       "253679                   1.0           1.0     1.0      0.0  ...            0   \n",
       "\n",
       "        Education_5  Education_6  Income_2  Income_3  Income_4  Income_5  \\\n",
       "0                 0            0         0         1         0         0   \n",
       "1                 0            1         0         0         0         0   \n",
       "2                 0            0         0         0         0         0   \n",
       "3                 0            0         0         0         0         0   \n",
       "4                 1            0         0         0         1         0   \n",
       "...             ...          ...       ...       ...       ...       ...   \n",
       "253675            0            1         0         0         0         0   \n",
       "253676            0            0         0         0         1         0   \n",
       "253677            1            0         1         0         0         0   \n",
       "253678            1            0         0         0         0         0   \n",
       "253679            0            1         1         0         0         0   \n",
       "\n",
       "        Income_6  Income_7  Income_8  \n",
       "0              0         0         0  \n",
       "1              0         0         0  \n",
       "2              0         0         1  \n",
       "3              1         0         0  \n",
       "4              0         0         0  \n",
       "...          ...       ...       ...  \n",
       "253675         0         1         0  \n",
       "253676         0         0         0  \n",
       "253677         0         0         0  \n",
       "253678         0         0         0  \n",
       "253679         0         0         0  \n",
       "\n",
       "[229781 rows x 45 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## read the raw data file\n",
    "df = pd.read_csv('raw_data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "df.head()\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# convert data types\n",
    "df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']] = df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']].astype(int)\n",
    "df.info()\n",
    "\n",
    "#slice the dataframe for feature and label\n",
    "df_copy = df.copy(deep=True)\n",
    "X, y = df_copy.iloc[:,1:], df_copy.iloc[:,0]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#get dummies\n",
    "def get_dummies(X):\n",
    "\n",
    "    # Identify discrete columns with more than 2 categories\n",
    "    discrete_columns = [col for col in X.columns if X[col].nunique() > 2 and X[col].dtype != 'float64']\n",
    "\n",
    "    # Create dummy variables for these columns\n",
    "    df_with_dummies = pd.get_dummies(X, columns=discrete_columns, drop_first=True)\n",
    "\n",
    "    return df_with_dummies\n",
    "X = get_dummies(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE technique\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_smote)\n",
    "X_scaled_test = scalar.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [0]\n",
      "accuracy : 0.8288055008540686  precision : 0.2762685002846895 \n",
      " recall : 0.3333333333333333  f1 : 0.3021299970452513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## This is the baseline dummy classifier which classifies all as the majority class\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_scaled, y_smote)\n",
    "y_dummy_prediction = dummy_majority.predict(X_scaled_test)\n",
    "\n",
    "## calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_dummy_prediction)\n",
    "precision = precision_score(y_test, y_dummy_prediction, average='macro')\n",
    "recall = recall_score(y_test, y_dummy_prediction, average='macro')\n",
    "f1 = f1_score(y_test, y_dummy_prediction, average='macro')\n",
    "print('Unique predicted labels: ', (np.unique(y_dummy_prediction)))\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.16143527030996704  precision : 0.4117341018685141 \n",
      " recall : 0.37725541414790453  f1 : 0.1523638900679455\n"
     ]
    }
   ],
   "source": [
    "# Moving forward with l2 logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training the logistic regression model\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "\n",
    "clf.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = clf.predict(X_scaled_test)\n",
    "y_pred_proba = clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bruce/Desktop/STATS 302/Group Project/SMOTE.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m knn\u001b[39m.\u001b[39mfit(X_scaled, y_smote)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Making predictions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m y_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(X_scaled_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m y_pred_proba \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mpredict_proba(X_scaled_test)[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Calculating metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:214\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    201\u001b[0m     \u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m        Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     neigh_dist, neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X)\n\u001b[1;32m    215\u001b[0m     classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m    216\u001b[0m     _y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:752\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 752\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    753\u001b[0m         pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m             X,\n\u001b[1;32m    755\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[1;32m    756\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[1;32m    757\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[1;32m    758\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    759\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[1;32m    760\u001b[0m         )\n\u001b[1;32m    761\u001b[0m     )\n\u001b[1;32m    763\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    764\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1726\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[39mif\u001b[39;00m reduce_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     chunk_size \u001b[39m=\u001b[39m D_chunk\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 1726\u001b[0m     D_chunk \u001b[39m=\u001b[39m reduce_func(D_chunk, sl\u001b[39m.\u001b[39;49mstart)\n\u001b[1;32m   1727\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[1;32m   1728\u001b[0m \u001b[39myield\u001b[39;00m D_chunk\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:634\u001b[0m, in \u001b[0;36mKNeighborsMixin._kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39m\"\"\"Reduce a chunk of distances to the nearest neighbors.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[39mCallback to :func:`sklearn.metrics.pairwise.pairwise_distances_chunked`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m    The neighbors indices.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    633\u001b[0m sample_range \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(dist\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])[:, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m--> 634\u001b[0m neigh_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margpartition(dist, n_neighbors \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    635\u001b[0m neigh_ind \u001b[39m=\u001b[39m neigh_ind[:, :n_neighbors]\n\u001b[1;32m    636\u001b[0m \u001b[39m# argpartition doesn't guarantee sorted order, so we sort again\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:839\u001b[0m, in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_argpartition_dispatcher)\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margpartition\u001b[39m(a, kth, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mintroselect\u001b[39m\u001b[39m'\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    765\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[39m    Perform an indirect partition along the given axis using the\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    algorithm specified by the `kind` keyword. It returns an array of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 839\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margpartition\u001b[39;49m\u001b[39m'\u001b[39;49m, kth, axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## we can see that the baseline model logistic regression perform poorly\n",
    "## try KNN classifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Setting up the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = knn.predict(X_scaled_test)\n",
    "y_pred_proba = knn.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.13191822701902886  precision : 0.2689370005348038 \n",
      " recall : 0.3423851455389945  f1 : 0.10489123343084951\n"
     ]
    }
   ],
   "source": [
    "## we can see that both logistic regression and KNN perform very poorly, lets try more models\n",
    "\n",
    "## Decision trees\n",
    "from sklearn import tree\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = tree_clf.predict(X_scaled_test)\n",
    "y_pred_proba = tree_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear support vector classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC(kernel='rbf')\n",
    "svc_clf.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svc_clf.predict(X_scaled_test)\n",
    "# y_pred_proba = svc_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.3378956186828849  precision : 0.4144583768120907 \n",
      " recall : 0.426148496525581  f1 : 0.2863866307802525\n"
     ]
    }
   ],
   "source": [
    "## implement the naive bayes algorithm\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = NB_clf.predict(X_scaled_test)\n",
    "y_pred_proba = NB_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.1501419820917607  precision : 0.05846769738381049 \n",
      " recall : 0.34115348890881503  f1 : 0.0998267579543138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## random forest prediction\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "rf_clf.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = rf_clf.predict(X_scaled_test)\n",
    "y_pred_proba = rf_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bruce/Desktop/STATS 302/Group Project/SMOTE.ipynb Cell 12\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m GradientBoostingClassifier\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m GBDT_clf \u001b[39m=\u001b[39m GradientBoostingClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m GBDT_clf\u001b[39m.\u001b[39;49mfit(X_scaled, y_smote)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Making predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/SMOTE.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_pred \u001b[39m=\u001b[39m GBDT_clf\u001b[39m.\u001b[39mpredict(X_scaled_test)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:586\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[1;32m    585\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[1;32m    587\u001b[0m     X,\n\u001b[1;32m    588\u001b[0m     y,\n\u001b[1;32m    589\u001b[0m     raw_predictions,\n\u001b[1;32m    590\u001b[0m     sample_weight,\n\u001b[1;32m    591\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[1;32m    592\u001b[0m     X_val,\n\u001b[1;32m    593\u001b[0m     y_val,\n\u001b[1;32m    594\u001b[0m     sample_weight_val,\n\u001b[1;32m    595\u001b[0m     begin_at_stage,\n\u001b[1;32m    596\u001b[0m     monitor,\n\u001b[1;32m    597\u001b[0m )\n\u001b[1;32m    599\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:663\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    656\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[1;32m    657\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    658\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    659\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[1;32m    664\u001b[0m     i,\n\u001b[1;32m    665\u001b[0m     X,\n\u001b[1;32m    666\u001b[0m     y,\n\u001b[1;32m    667\u001b[0m     raw_predictions,\n\u001b[1;32m    668\u001b[0m     sample_weight,\n\u001b[1;32m    669\u001b[0m     sample_mask,\n\u001b[1;32m    670\u001b[0m     random_state,\n\u001b[1;32m    671\u001b[0m     X_csc,\n\u001b[1;32m    672\u001b[0m     X_csr,\n\u001b[1;32m    673\u001b[0m )\n\u001b[1;32m    675\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:246\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    243\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m    245\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[0;32m--> 246\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    248\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[1;32m    249\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    250\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[1;32m    251\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m   1279\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1280\u001b[0m ):\n\u001b[1;32m   1281\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \n\u001b[1;32m   1283\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1316\u001b[0m         X,\n\u001b[1;32m   1317\u001b[0m         y,\n\u001b[1;32m   1318\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1319\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1320\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m   1321\u001b[0m     )\n\u001b[1;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## gradient boosing decision trees (GBDT)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBDT_clf = GradientBoostingClassifier(n_estimators=300)\n",
    "GBDT_clf.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = GBDT_clf.predict(X_scaled_test)\n",
    "y_pred_proba = GBDT_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=300)\n",
    "ada_clf.fit(X_scaled, y_smote)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = ada_clf.predict(X_scaled_test)\n",
    "y_pred_proba = ada_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
