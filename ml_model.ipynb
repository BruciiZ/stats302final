{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe has 253680 rows and 22 columns\n",
      "['Diabetes_012' 'HighBP' 'HighChol' 'CholCheck' 'BMI' 'Smoker' 'Stroke'\n",
      " 'HeartDiseaseorAttack' 'PhysActivity' 'Fruits' 'Veggies'\n",
      " 'HvyAlcoholConsump' 'AnyHealthcare' 'NoDocbcCost' 'GenHlth' 'MentHlth'\n",
      " 'PhysHlth' 'DiffWalk' 'Sex' 'Age' 'Education' 'Income']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the raw data file\n",
    "df = pd.read_csv('raw_data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "print('The dataframe has {} rows and {} columns'.format(df.shape[0],df.shape[1]))\n",
    "print(df.columns.values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_012          253680 non-null  float64\n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "## check out the variable type of each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_012          253680 non-null  int64  \n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  int64  \n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  int64  \n",
      " 20  Education             253680 non-null  int64  \n",
      " 21  Income                253680 non-null  int64  \n",
      "dtypes: float64(17), int64(5)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "#convert data types\n",
    "df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']] = df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253680, 21)\n",
      "(253680,)\n"
     ]
    }
   ],
   "source": [
    "#slice the dataframe for feature and label\n",
    "X, y = df.iloc[:,1:], df.iloc[:,0]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_4</th>\n",
       "      <th>Education_5</th>\n",
       "      <th>Education_6</th>\n",
       "      <th>Income_2</th>\n",
       "      <th>Income_3</th>\n",
       "      <th>Income_4</th>\n",
       "      <th>Income_5</th>\n",
       "      <th>Income_6</th>\n",
       "      <th>Income_7</th>\n",
       "      <th>Income_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  HeartDiseaseorAttack  \\\n",
       "0     1.0       1.0        1.0  40.0     1.0     0.0                   0.0   \n",
       "1     0.0       0.0        0.0  25.0     1.0     0.0                   0.0   \n",
       "2     1.0       1.0        1.0  28.0     0.0     0.0                   0.0   \n",
       "3     1.0       0.0        1.0  27.0     0.0     0.0                   0.0   \n",
       "4     1.0       1.0        1.0  24.0     0.0     0.0                   0.0   \n",
       "\n",
       "   PhysActivity  Fruits  Veggies  ...  Education_4  Education_5  Education_6  \\\n",
       "0           0.0     0.0      1.0  ...            1            0            0   \n",
       "1           1.0     0.0      0.0  ...            0            0            1   \n",
       "2           0.0     1.0      0.0  ...            1            0            0   \n",
       "3           1.0     1.0      1.0  ...            0            0            0   \n",
       "4           1.0     1.0      1.0  ...            0            1            0   \n",
       "\n",
       "   Income_2  Income_3  Income_4  Income_5  Income_6  Income_7  Income_8  \n",
       "0         0         1         0         0         0         0         0  \n",
       "1         0         0         0         0         0         0         0  \n",
       "2         0         0         0         0         0         0         1  \n",
       "3         0         0         0         0         1         0         0  \n",
       "4         0         0         1         0         0         0         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify discrete columns with more than 2 categories\n",
    "discrete_columns = [col for col in X.columns if X[col].nunique() > 2 and X[col].dtype != 'float64']\n",
    "\n",
    "# Create dummy variables for these columns\n",
    "df_with_dummies = pd.get_dummies(X, columns=discrete_columns, drop_first=True)\n",
    "\n",
    "df_with_dummies.head()\n",
    "\n",
    "X = df_with_dummies\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke',\n",
       "       'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'MentHlth',\n",
       "       'PhysHlth', 'DiffWalk', 'Sex', 'GenHlth_2', 'GenHlth_3', 'GenHlth_4',\n",
       "       'GenHlth_5', 'Age_2', 'Age_3', 'Age_4', 'Age_5', 'Age_6', 'Age_7',\n",
       "       'Age_8', 'Age_9', 'Age_10', 'Age_11', 'Age_12', 'Age_13', 'Education_2',\n",
       "       'Education_3', 'Education_4', 'Education_5', 'Education_6', 'Income_2',\n",
       "       'Income_3', 'Income_4', 'Income_5', 'Income_6', 'Income_7', 'Income_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8434839167455062  precision : 0.71146511780834 \n",
      " recall : 0.8434839167455062  f1 : 0.7718701653382073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## This is the baseline dummy classifier which classifies all as the majority class\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "y_dummy_prediction = dummy_majority.predict(X_test)\n",
    "\n",
    "## calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_dummy_prediction)\n",
    "precision = precision_score(y_test, y_dummy_prediction, average='weighted')\n",
    "recall = recall_score(y_test, y_dummy_prediction, average='weighted')\n",
    "f1 = f1_score(y_test, y_dummy_prediction, average='weighted')\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# paramSpace = {'penalty' : [\"l1\", \"l2\", \"elasticnet\", None]}\n",
    "# logit = LogisticRegression()\n",
    "# clf = GridSearchCV(logit, param_grid = paramSpace, scoring = 'recall_micro', cv=5)\n",
    "# clf.fit(X, y)\n",
    "# print(clf.best_params_) ## the best parameter\n",
    "# print(clf.best_score_) ## the best recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8502049826553137  precision : 0.805773056526727 \n",
      " recall : 0.8502049826553137  f1 : 0.8121027811294743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Moving forward with l2 logistic regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# # Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "# Training the logistic regression model\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "\n",
    "\n",
    "# cross_score = cross_val_score(clf, X, y, cv=5, scoring = 'recall_weighted')\n",
    "# print(cross_score)\n",
    "# print(cross_score.mean())\n",
    "\n",
    "clf.fit(X_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = clf.predict(X_scaled_test)\n",
    "y_pred_proba = clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# # ROC Curve and AUC\n",
    "# fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # Plotting the ROC Curve\n",
    "# plt.figure()\n",
    "# plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/bruce/Desktop/STATS 302/Group Project/ml_model.ipynb Cell 11\u001b[0m line \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/ml_model.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m knn\u001b[39m.\u001b[39mfit(X_scaled, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/ml_model.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Making predictions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/ml_model.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m y_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(X_scaled_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/ml_model.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m y_pred_proba \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mpredict_proba(X_scaled_test)[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/ml_model.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Calculating metrics\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:214\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    201\u001b[0m     \u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m        Class labels for each data sample.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     neigh_dist, neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X)\n\u001b[1;32m    215\u001b[0m     classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[1;32m    216\u001b[0m     _y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:752\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[0;32m--> 752\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\n\u001b[1;32m    753\u001b[0m         pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m             X,\n\u001b[1;32m    755\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_X,\n\u001b[1;32m    756\u001b[0m             reduce_func\u001b[39m=\u001b[39;49mreduce_func,\n\u001b[1;32m    757\u001b[0m             metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffective_metric_,\n\u001b[1;32m    758\u001b[0m             n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    759\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds,\n\u001b[1;32m    760\u001b[0m         )\n\u001b[1;32m    761\u001b[0m     )\n\u001b[1;32m    763\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    764\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1726\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[39mif\u001b[39;00m reduce_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     chunk_size \u001b[39m=\u001b[39m D_chunk\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 1726\u001b[0m     D_chunk \u001b[39m=\u001b[39m reduce_func(D_chunk, sl\u001b[39m.\u001b[39;49mstart)\n\u001b[1;32m   1727\u001b[0m     _check_chunk_size(D_chunk, chunk_size)\n\u001b[1;32m   1728\u001b[0m \u001b[39myield\u001b[39;00m D_chunk\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py:634\u001b[0m, in \u001b[0;36mKNeighborsMixin._kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39m\"\"\"Reduce a chunk of distances to the nearest neighbors.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[39mCallback to :func:`sklearn.metrics.pairwise.pairwise_distances_chunked`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m    The neighbors indices.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    633\u001b[0m sample_range \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(dist\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])[:, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m--> 634\u001b[0m neigh_ind \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margpartition(dist, n_neighbors \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    635\u001b[0m neigh_ind \u001b[39m=\u001b[39m neigh_ind[:, :n_neighbors]\n\u001b[1;32m    636\u001b[0m \u001b[39m# argpartition doesn't guarantee sorted order, so we sort again\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:839\u001b[0m, in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_argpartition_dispatcher)\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39margpartition\u001b[39m(a, kth, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mintroselect\u001b[39m\u001b[39m'\u001b[39m, order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    765\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    766\u001b[0m \u001b[39m    Perform an indirect partition along the given axis using the\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    algorithm specified by the `kind` keyword. It returns an array of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 839\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39margpartition\u001b[39;49m\u001b[39m'\u001b[39;49m, kth, axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## we can see that the baseline model logistic regression perform poorly\n",
    "## try KNN classifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "\n",
    "# Setting up the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = knn.predict(X_scaled_test)\n",
    "y_pred_proba = knn.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7710698517817723  precision : 0.7810365360388878 \n",
      " recall : 0.7710698517817723  f1 : 0.7759079934926593\n"
     ]
    }
   ],
   "source": [
    "## we can see that both logistic regression and KNN perform very poorly, lets try more models\n",
    "\n",
    "## Decision trees\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(X_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = tree_clf.predict(X_scaled_test)\n",
    "y_pred_proba = tree_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "\n",
    "svc_clf = LinearSVC()\n",
    "svc_clf.fit(scalar.fit_transform(X_train), y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svc_clf.predict(scalar.fit_transform(X_test))\n",
    "y_pred_proba = svc_clf.predict_proba(StandardScaler.fit_transform(X_test))[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7078405865657521  precision : 0.8183586222130868 \n",
      " recall : 0.7078405865657521  f1 : 0.7434552315836094\n"
     ]
    }
   ],
   "source": [
    "## implement the naive bayes algorithm\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = NB_clf.predict(X_scaled_test)\n",
    "y_pred_proba = NB_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8434050772626932  precision : 0.7963904494527871 \n",
      " recall : 0.8434050772626932  f1 : 0.8085535972051645\n"
     ]
    }
   ],
   "source": [
    "## random forest prediction\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "rf_clf.fit(X_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = rf_clf.predict(X_scaled_test)\n",
    "y_pred_proba = rf_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8505794701986755  precision : 0.8069403215493294 \n",
      " recall : 0.8505794701986755  f1 : 0.8148903576743735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## gradient boosing decision trees (GBDT)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "\n",
    "GBDT_clf = GradientBoostingClassifier(n_estimators=300)\n",
    "GBDT_clf.fit(X_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = GBDT_clf.predict(X_scaled_test)\n",
    "y_pred_proba = GBDT_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.8501261431725008  precision : 0.8068891433108292 \n",
      " recall : 0.8501261431725008  f1 : 0.8161955884374462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_train)\n",
    "X_scaled_test = scalar.fit_transform(X_test)\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=300)\n",
    "ada_clf.fit(X_scaled, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = ada_clf.predict(X_scaled_test)\n",
    "y_pred_proba = ada_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.6946, Recall: 0.7779\n",
      "Epoch [2/500], Loss: 0.6895, Recall: 0.8477\n",
      "Epoch [3/500], Loss: 0.6864, Recall: 0.8494\n",
      "Epoch [4/500], Loss: 0.6925, Recall: 0.8502\n",
      "Epoch [5/500], Loss: 0.7027, Recall: 0.8508\n",
      "Epoch [6/500], Loss: 0.6860, Recall: 0.8509\n",
      "Epoch [7/500], Loss: 0.6857, Recall: 0.8517\n",
      "Epoch [8/500], Loss: 0.7079, Recall: 0.8521\n",
      "Epoch [9/500], Loss: 0.6911, Recall: 0.8524\n",
      "Epoch [10/500], Loss: 0.7059, Recall: 0.8530\n",
      "Epoch [11/500], Loss: 0.6905, Recall: 0.8536\n",
      "Epoch [12/500], Loss: 0.6694, Recall: 0.8538\n",
      "Epoch [13/500], Loss: 0.7093, Recall: 0.8542\n",
      "Epoch [14/500], Loss: 0.6904, Recall: 0.8544\n",
      "Epoch [15/500], Loss: 0.6982, Recall: 0.8551\n",
      "Epoch [16/500], Loss: 0.7034, Recall: 0.8556\n",
      "Epoch [17/500], Loss: 0.7046, Recall: 0.8557\n",
      "Epoch [18/500], Loss: 0.6787, Recall: 0.8562\n",
      "Epoch [19/500], Loss: 0.6912, Recall: 0.8569\n",
      "Epoch [20/500], Loss: 0.6973, Recall: 0.8572\n",
      "Epoch [21/500], Loss: 0.6853, Recall: 0.8577\n",
      "Epoch [22/500], Loss: 0.6829, Recall: 0.8580\n",
      "Epoch [23/500], Loss: 0.6752, Recall: 0.8588\n",
      "Epoch [24/500], Loss: 0.7187, Recall: 0.8592\n",
      "Epoch [25/500], Loss: 0.6809, Recall: 0.8596\n",
      "Epoch [26/500], Loss: 0.6865, Recall: 0.8601\n",
      "Epoch [27/500], Loss: 0.6852, Recall: 0.8604\n",
      "Epoch [28/500], Loss: 0.6895, Recall: 0.8604\n",
      "Epoch [29/500], Loss: 0.7078, Recall: 0.8608\n",
      "Epoch [30/500], Loss: 0.6915, Recall: 0.8612\n",
      "Epoch [31/500], Loss: 0.6980, Recall: 0.8618\n",
      "Epoch [32/500], Loss: 0.6971, Recall: 0.8620\n",
      "Epoch [33/500], Loss: 0.6954, Recall: 0.8622\n",
      "Epoch [34/500], Loss: 0.6673, Recall: 0.8626\n",
      "Epoch [35/500], Loss: 0.6940, Recall: 0.8629\n",
      "Epoch [36/500], Loss: 0.6871, Recall: 0.8636\n",
      "Epoch [37/500], Loss: 0.6901, Recall: 0.8632\n",
      "Epoch [38/500], Loss: 0.6761, Recall: 0.8637\n",
      "Epoch [39/500], Loss: 0.7008, Recall: 0.8638\n",
      "Epoch [40/500], Loss: 0.6882, Recall: 0.8642\n",
      "Epoch [41/500], Loss: 0.6935, Recall: 0.8645\n",
      "Epoch [42/500], Loss: 0.6961, Recall: 0.8647\n",
      "Epoch [43/500], Loss: 0.7115, Recall: 0.8652\n",
      "Epoch [44/500], Loss: 0.6820, Recall: 0.8651\n",
      "Epoch [45/500], Loss: 0.6875, Recall: 0.8654\n",
      "Epoch [46/500], Loss: 0.6755, Recall: 0.8654\n",
      "Epoch [47/500], Loss: 0.6845, Recall: 0.8657\n",
      "Epoch [48/500], Loss: 0.6966, Recall: 0.8660\n",
      "Epoch [49/500], Loss: 0.6709, Recall: 0.8660\n",
      "Epoch [50/500], Loss: 0.6780, Recall: 0.8664\n",
      "Epoch [51/500], Loss: 0.6954, Recall: 0.8664\n",
      "Epoch [52/500], Loss: 0.6889, Recall: 0.8665\n",
      "Epoch [53/500], Loss: 0.6923, Recall: 0.8666\n",
      "Epoch [54/500], Loss: 0.6649, Recall: 0.8667\n",
      "Epoch [55/500], Loss: 0.6912, Recall: 0.8671\n",
      "Epoch [56/500], Loss: 0.6844, Recall: 0.8669\n",
      "Epoch [57/500], Loss: 0.6780, Recall: 0.8674\n",
      "Epoch [58/500], Loss: 0.6840, Recall: 0.8672\n",
      "Epoch [59/500], Loss: 0.6758, Recall: 0.8676\n",
      "Epoch [60/500], Loss: 0.6769, Recall: 0.8678\n",
      "Epoch [61/500], Loss: 0.6791, Recall: 0.8676\n",
      "Epoch [62/500], Loss: 0.6740, Recall: 0.8680\n",
      "Epoch [63/500], Loss: 0.7008, Recall: 0.8681\n",
      "Epoch [64/500], Loss: 0.6930, Recall: 0.8680\n",
      "Epoch [65/500], Loss: 0.6924, Recall: 0.8680\n",
      "Epoch [66/500], Loss: 0.6846, Recall: 0.8682\n",
      "Epoch [67/500], Loss: 0.6992, Recall: 0.8682\n",
      "Epoch [68/500], Loss: 0.6802, Recall: 0.8681\n",
      "Epoch [69/500], Loss: 0.6922, Recall: 0.8681\n",
      "Epoch [70/500], Loss: 0.6579, Recall: 0.8684\n",
      "Epoch [71/500], Loss: 0.6671, Recall: 0.8686\n",
      "Epoch [72/500], Loss: 0.6931, Recall: 0.8688\n",
      "Epoch [73/500], Loss: 0.6943, Recall: 0.8686\n",
      "Epoch [74/500], Loss: 0.6939, Recall: 0.8685\n",
      "Epoch [75/500], Loss: 0.6730, Recall: 0.8689\n",
      "Epoch [76/500], Loss: 0.6725, Recall: 0.8689\n",
      "Epoch [77/500], Loss: 0.6778, Recall: 0.8689\n",
      "Epoch [78/500], Loss: 0.6735, Recall: 0.8690\n",
      "Epoch [79/500], Loss: 0.6769, Recall: 0.8687\n",
      "Epoch [80/500], Loss: 0.6746, Recall: 0.8690\n",
      "Epoch [81/500], Loss: 0.7024, Recall: 0.8692\n",
      "Epoch [82/500], Loss: 0.6722, Recall: 0.8691\n",
      "Epoch [83/500], Loss: 0.6633, Recall: 0.8697\n",
      "Epoch [84/500], Loss: 0.6832, Recall: 0.8694\n",
      "Epoch [85/500], Loss: 0.6796, Recall: 0.8692\n",
      "Epoch [86/500], Loss: 0.6622, Recall: 0.8697\n",
      "Epoch [87/500], Loss: 0.6740, Recall: 0.8692\n",
      "Epoch [88/500], Loss: 0.6938, Recall: 0.8697\n",
      "Epoch [89/500], Loss: 0.6738, Recall: 0.8697\n",
      "Epoch [90/500], Loss: 0.6836, Recall: 0.8697\n",
      "Epoch [91/500], Loss: 0.6928, Recall: 0.8700\n",
      "Epoch [92/500], Loss: 0.6843, Recall: 0.8696\n",
      "Epoch [93/500], Loss: 0.6913, Recall: 0.8697\n",
      "Epoch [94/500], Loss: 0.6843, Recall: 0.8699\n",
      "Epoch [95/500], Loss: 0.6855, Recall: 0.8699\n",
      "Epoch [96/500], Loss: 0.6828, Recall: 0.8699\n",
      "Epoch [97/500], Loss: 0.6668, Recall: 0.8700\n",
      "Epoch [98/500], Loss: 0.6982, Recall: 0.8698\n",
      "Epoch [99/500], Loss: 0.6764, Recall: 0.8695\n",
      "Epoch [100/500], Loss: 0.6852, Recall: 0.8702\n",
      "Epoch [101/500], Loss: 0.6904, Recall: 0.8703\n",
      "Epoch [102/500], Loss: 0.6722, Recall: 0.8700\n",
      "Epoch [103/500], Loss: 0.6763, Recall: 0.8698\n",
      "Epoch [104/500], Loss: 0.6718, Recall: 0.8705\n",
      "Epoch [105/500], Loss: 0.6804, Recall: 0.8702\n",
      "Epoch [106/500], Loss: 0.6894, Recall: 0.8700\n",
      "Epoch [107/500], Loss: 0.6955, Recall: 0.8705\n",
      "Epoch [108/500], Loss: 0.6723, Recall: 0.8706\n",
      "Epoch [109/500], Loss: 0.6933, Recall: 0.8705\n",
      "Epoch [110/500], Loss: 0.6742, Recall: 0.8705\n",
      "Epoch [111/500], Loss: 0.6864, Recall: 0.8704\n",
      "Epoch [112/500], Loss: 0.6876, Recall: 0.8707\n",
      "Epoch [113/500], Loss: 0.6952, Recall: 0.8705\n",
      "Epoch [114/500], Loss: 0.6826, Recall: 0.8705\n",
      "Epoch [115/500], Loss: 0.6833, Recall: 0.8705\n",
      "Epoch [116/500], Loss: 0.6811, Recall: 0.8702\n",
      "Epoch [117/500], Loss: 0.6842, Recall: 0.8702\n",
      "Epoch [118/500], Loss: 0.6913, Recall: 0.8706\n",
      "Epoch [119/500], Loss: 0.6819, Recall: 0.8702\n",
      "Epoch [120/500], Loss: 0.6743, Recall: 0.8703\n",
      "Epoch [121/500], Loss: 0.6684, Recall: 0.8706\n",
      "Epoch [122/500], Loss: 0.6929, Recall: 0.8705\n",
      "Epoch [123/500], Loss: 0.6820, Recall: 0.8704\n",
      "Epoch [124/500], Loss: 0.6649, Recall: 0.8709\n",
      "Epoch [125/500], Loss: 0.6643, Recall: 0.8703\n",
      "Epoch [126/500], Loss: 0.6913, Recall: 0.8707\n",
      "Epoch [127/500], Loss: 0.6665, Recall: 0.8709\n",
      "Epoch [128/500], Loss: 0.6852, Recall: 0.8710\n",
      "Epoch [129/500], Loss: 0.6851, Recall: 0.8708\n",
      "Epoch [130/500], Loss: 0.6756, Recall: 0.8708\n",
      "Epoch [131/500], Loss: 0.6652, Recall: 0.8709\n",
      "Epoch [132/500], Loss: 0.6986, Recall: 0.8703\n",
      "Epoch [133/500], Loss: 0.6707, Recall: 0.8706\n",
      "Epoch [134/500], Loss: 0.6815, Recall: 0.8708\n",
      "Epoch [135/500], Loss: 0.6995, Recall: 0.8707\n",
      "Epoch [136/500], Loss: 0.6832, Recall: 0.8710\n",
      "Epoch [137/500], Loss: 0.6687, Recall: 0.8707\n",
      "Epoch [138/500], Loss: 0.6728, Recall: 0.8702\n",
      "Epoch [139/500], Loss: 0.6763, Recall: 0.8706\n",
      "Epoch [140/500], Loss: 0.6873, Recall: 0.8704\n",
      "Epoch [141/500], Loss: 0.6916, Recall: 0.8705\n",
      "Epoch [142/500], Loss: 0.7014, Recall: 0.8713\n",
      "Epoch [143/500], Loss: 0.6762, Recall: 0.8712\n",
      "Epoch [144/500], Loss: 0.7033, Recall: 0.8711\n",
      "Epoch [145/500], Loss: 0.6580, Recall: 0.8713\n",
      "Epoch [146/500], Loss: 0.6856, Recall: 0.8712\n",
      "Epoch [147/500], Loss: 0.6830, Recall: 0.8713\n",
      "Epoch [148/500], Loss: 0.6867, Recall: 0.8710\n",
      "Epoch [149/500], Loss: 0.6866, Recall: 0.8709\n",
      "Epoch [150/500], Loss: 0.6649, Recall: 0.8706\n",
      "Epoch [151/500], Loss: 0.6887, Recall: 0.8714\n",
      "Epoch [152/500], Loss: 0.6845, Recall: 0.8713\n",
      "Epoch [153/500], Loss: 0.6696, Recall: 0.8713\n",
      "Epoch [154/500], Loss: 0.6775, Recall: 0.8709\n",
      "Epoch [155/500], Loss: 0.6968, Recall: 0.8706\n",
      "Epoch [156/500], Loss: 0.6935, Recall: 0.8712\n",
      "Epoch [157/500], Loss: 0.6870, Recall: 0.8709\n",
      "Epoch [158/500], Loss: 0.6910, Recall: 0.8714\n",
      "Epoch [159/500], Loss: 0.6621, Recall: 0.8716\n",
      "Epoch [160/500], Loss: 0.6659, Recall: 0.8712\n",
      "Epoch [161/500], Loss: 0.6834, Recall: 0.8713\n",
      "Epoch [162/500], Loss: 0.6999, Recall: 0.8714\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(45, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        self.fc4 = nn.Linear(16, 3)\n",
    "\n",
    "        # Loss Function\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, data_loader, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            all_predictions = []\n",
    "            all_labels = []\n",
    "\n",
    "            for batch in data_loader:\n",
    "                inputs, labels = batch\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Save predictions and labels for calculating recall\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Recall: {recall:.4f}')\n",
    "\n",
    "    def predict(self, sample_data):\n",
    "        self.eval()  # Set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            predictions = self(sample_data)\n",
    "            predicted_class = torch.argmax(predictions, dim=1)\n",
    "            return predicted_class.item()\n",
    "\n",
    "# Example usage\n",
    "# model = NeuralNetwork()\n",
    "# model.train_model(data_loader, num_epochs)\n",
    "# prediction = model.predict(sample_data)\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming X and y are your features and labels respectively\n",
    "# Convert your data to PyTorch tensors if they are not already\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.int64)\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 1000  # You can adjust this according to your needs\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.train_model(data_loader, num_epochs = 500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
