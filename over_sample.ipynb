{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 229781 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_012          229781 non-null  int64  \n",
      " 1   HighBP                229781 non-null  float64\n",
      " 2   HighChol              229781 non-null  float64\n",
      " 3   CholCheck             229781 non-null  float64\n",
      " 4   BMI                   229781 non-null  float64\n",
      " 5   Smoker                229781 non-null  float64\n",
      " 6   Stroke                229781 non-null  float64\n",
      " 7   HeartDiseaseorAttack  229781 non-null  float64\n",
      " 8   PhysActivity          229781 non-null  float64\n",
      " 9   Fruits                229781 non-null  float64\n",
      " 10  Veggies               229781 non-null  float64\n",
      " 11  HvyAlcoholConsump     229781 non-null  float64\n",
      " 12  AnyHealthcare         229781 non-null  float64\n",
      " 13  NoDocbcCost           229781 non-null  float64\n",
      " 14  GenHlth               229781 non-null  int64  \n",
      " 15  MentHlth              229781 non-null  float64\n",
      " 16  PhysHlth              229781 non-null  float64\n",
      " 17  DiffWalk              229781 non-null  float64\n",
      " 18  Sex                   229781 non-null  float64\n",
      " 19  Age                   229781 non-null  int64  \n",
      " 20  Education             229781 non-null  int64  \n",
      " 21  Income                229781 non-null  int64  \n",
      "dtypes: float64(17), int64(5)\n",
      "memory usage: 40.3 MB\n",
      "(229781, 21)\n",
      "(229781,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>Education_4</th>\n",
       "      <th>Education_5</th>\n",
       "      <th>Education_6</th>\n",
       "      <th>Income_2</th>\n",
       "      <th>Income_3</th>\n",
       "      <th>Income_4</th>\n",
       "      <th>Income_5</th>\n",
       "      <th>Income_6</th>\n",
       "      <th>Income_7</th>\n",
       "      <th>Income_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229781 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0          1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1          0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2          1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3          1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4          1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "...        ...       ...        ...   ...     ...     ...   \n",
       "253675     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  Education_4  \\\n",
       "0                        0.0           0.0     0.0      1.0  ...            1   \n",
       "1                        0.0           1.0     0.0      0.0  ...            0   \n",
       "2                        0.0           0.0     1.0      0.0  ...            1   \n",
       "3                        0.0           1.0     1.0      1.0  ...            0   \n",
       "4                        0.0           1.0     1.0      1.0  ...            0   \n",
       "...                      ...           ...     ...      ...  ...          ...   \n",
       "253675                   0.0           0.0     1.0      1.0  ...            0   \n",
       "253676                   0.0           0.0     0.0      0.0  ...            0   \n",
       "253677                   0.0           1.0     1.0      0.0  ...            0   \n",
       "253678                   0.0           0.0     1.0      1.0  ...            0   \n",
       "253679                   1.0           1.0     1.0      0.0  ...            0   \n",
       "\n",
       "        Education_5  Education_6  Income_2  Income_3  Income_4  Income_5  \\\n",
       "0                 0            0         0         1         0         0   \n",
       "1                 0            1         0         0         0         0   \n",
       "2                 0            0         0         0         0         0   \n",
       "3                 0            0         0         0         0         0   \n",
       "4                 1            0         0         0         1         0   \n",
       "...             ...          ...       ...       ...       ...       ...   \n",
       "253675            0            1         0         0         0         0   \n",
       "253676            0            0         0         0         1         0   \n",
       "253677            1            0         1         0         0         0   \n",
       "253678            1            0         0         0         0         0   \n",
       "253679            0            1         1         0         0         0   \n",
       "\n",
       "        Income_6  Income_7  Income_8  \n",
       "0              0         0         0  \n",
       "1              0         0         0  \n",
       "2              0         0         1  \n",
       "3              1         0         0  \n",
       "4              0         0         0  \n",
       "...          ...       ...       ...  \n",
       "253675         0         1         0  \n",
       "253676         0         0         0  \n",
       "253677         0         0         0  \n",
       "253678         0         0         0  \n",
       "253679         0         0         0  \n",
       "\n",
       "[229781 rows x 45 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## read the raw data file\n",
    "df = pd.read_csv('raw_data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "df.head()\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# convert data types\n",
    "df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']] = df[['Diabetes_012','GenHlth', 'Age', 'Education','Income']].astype(int)\n",
    "df.info()\n",
    "\n",
    "#slice the dataframe for feature and label\n",
    "df_copy = df.copy(deep=True)\n",
    "X, y = df_copy.iloc[:,1:], df_copy.iloc[:,0]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#get dummies\n",
    "def get_dummies(X):\n",
    "\n",
    "    # Identify discrete columns with more than 2 categories\n",
    "    discrete_columns = [col for col in X.columns if X[col].nunique() > 2 and X[col].dtype != 'float64']\n",
    "\n",
    "    # Create dummy variables for these columns\n",
    "    df_with_dummies = pd.get_dummies(X, columns=discrete_columns, drop_first=True)\n",
    "\n",
    "    return df_with_dummies\n",
    "X = get_dummies(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving forward with l2 logistic regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# define oversampling strategy\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_over, y_over = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    152043\n",
       "2    152043\n",
       "1    152043\n",
       "Name: Diabetes_012, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## oversample succeed\n",
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_over)\n",
    "X_scaled_test = scalar.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [0]\n",
      "accuracy : 0.8271210044171726  precision : 0.27570700147239086 \n",
      " recall : 0.3333333333333333  f1 : 0.30179391600868577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## This is the baseline dummy classifier which classifies all as the majority class\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_scaled, y_over)\n",
    "y_dummy_prediction = dummy_majority.predict(X_scaled_test)\n",
    "\n",
    "## calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_dummy_prediction)\n",
    "precision = precision_score(y_test, y_dummy_prediction, average='macro')\n",
    "recall = recall_score(y_test, y_dummy_prediction, average='macro')\n",
    "f1 = f1_score(y_test, y_dummy_prediction, average='macro')\n",
    "print('Unique predicted labels: ', (np.unique(y_dummy_prediction)))\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.5158735339556542  precision : 0.4305767607376667 \n",
      " recall : 0.49825467012528074  f1 : 0.37187624370243993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Moving forward with l2 logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training the logistic regression model\n",
    "clf = LogisticRegression(penalty='l2')\n",
    "\n",
    "clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = clf.predict(X_scaled_test)\n",
    "y_pred_proba = clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6360075722958418  precision : 0.3965135266411282 \n",
      " recall : 0.44062471559926775  f1 : 0.38848327724681336\n"
     ]
    }
   ],
   "source": [
    "## we can see that the baseline model logistic regression perform poorly\n",
    "## try KNN classifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Setting up the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "knn.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = knn.predict(X_scaled_test)\n",
    "y_pred_proba = knn.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.7365363274365168  precision : 0.38819800948918304 \n",
      " recall : 0.39423082774631113  f1 : 0.39059341247247525\n"
     ]
    }
   ],
   "source": [
    "## we can see that both logistic regression and KNN perform very poorly, lets try more models\n",
    "\n",
    "## Decision trees\n",
    "from sklearn import tree\n",
    "\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = tree_clf.predict(X_scaled_test)\n",
    "y_pred_proba = tree_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear support vector classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_clf = SVC(kernel='rbf')\n",
    "svc_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = svc_clf.predict(X_scaled_test)\n",
    "y_pred_proba = svc_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.5388297756598559  precision : 0.4087960216518305 \n",
      " recall : 0.4697972837107261  f1 : 0.36087536776708623\n"
     ]
    }
   ],
   "source": [
    "## implement the naive bayes algorithm\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = NB_clf.predict(X_scaled_test)\n",
    "y_pred_proba = NB_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.816611180016102  precision : 0.4457947826499265 \n",
      " recall : 0.42451176258655626  f1 : 0.42976350387690515\n"
     ]
    }
   ],
   "source": [
    "## random forest prediction\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "rf_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = rf_clf.predict(X_scaled_test)\n",
    "y_pred_proba = rf_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6117240028722501  precision : 0.44217302727755037 \n",
      " recall : 0.5133180217151039  f1 : 0.41728635264479114\n"
     ]
    }
   ],
   "source": [
    "## gradient boosing decision trees (GBDT)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBDT_clf = GradientBoostingClassifier(n_estimators=300)\n",
    "GBDT_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = GBDT_clf.predict(X_scaled_test)\n",
    "y_pred_proba = GBDT_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.6166198838044259  precision : 0.44123649529048753 \n",
      " recall : 0.51405201132797  f1 : 0.4187735255441163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(n_estimators=300)\n",
    "ada_clf.fit(X_scaled, y_over)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = ada_clf.predict(X_scaled_test)\n",
    "y_pred_proba = ada_clf.predict_proba(X_scaled_test)[:, 1]\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Performing 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(knn, X, y, cv=5)\n",
    "# cv_scores\n",
    "\n",
    "print('accuracy : %s  precision : %s \\n recall : %s  f1 : %s'\n",
    "      % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.fc1 = nn.Linear(45, 64)\n",
    "        # Second hidden layer\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        # Third hidden layer\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        # Output layer\n",
    "        self.fc4 = nn.Linear(16, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply ReLU activation function after each hidden layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # Apply softmax to the output layer\n",
    "        x = F.softmax(self.fc4(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming X and y are your features and labels respectively\n",
    "# Convert your data to PyTorch tensors if they are not already\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_over, dtype=torch.int64)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 183824  # You can adjust this according to your needs\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "X_tensor_test = torch.tensor(X_scaled_test, dtype=torch.float32)\n",
    "y_tensor_test = torch.tensor(y_test.to_numpy(), dtype=torch.int64)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor_test, y_tensor_test)\n",
    "\n",
    "# Create a DataLoader\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/bruce/Desktop/STATS 302/Group Project/over_sample.ipynb Cell 17\u001b[0m line \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Example training loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m500\u001b[39m):  \u001b[39m# num_epochs is the number of times you go through the entire dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# all_predictions = []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# all_labels = []\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:  \u001b[39m# data_loader is your PyTorch DataLoader with training data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         inputs, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         \u001b[39m# inputs = inputs.to('mps:0')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39m# labels = labels.to('mps:0')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/bruce/Desktop/STATS%20302/Group%20Project/over_sample.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39m# Zero the parameter gradients\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the neural network\n",
    "model = NeuralNetwork()\n",
    "# model = model.to('mps:0')\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predictions.extend(predicted.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    return recall\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(500):  # num_epochs is the number of times you go through the entire dataset\n",
    "    # all_predictions = []\n",
    "    # all_labels = []\n",
    "    for batch in train_loader:  # data_loader is your PyTorch DataLoader with training data\n",
    "        inputs, labels = batch\n",
    "        # inputs = inputs.to('mps:0')\n",
    "        # labels = labels.to('mps:0')\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    recall = evaluate_model(model, test_loader)\n",
    "    print(f'Epoch {epoch+1}/500, Loss: {loss.item():.4f}, Macro Recall: {recall:.4f}')\n",
    "\n",
    "\n",
    "    #     _, predicted = torch.max(outputs.data, 1)\n",
    "    #     all_predictions.extend(predicted.cpu().numpy())\n",
    "    #     all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # # Calculate recall\n",
    "    # recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    # print(f'Epoch [{epoch+1}/{500}], Loss: {loss.item():.4f}, Recall: {recall:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
